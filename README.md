# Sales Data Cleaning & Profiling Project

This project demonstrates a complete data processing workflow using a public e-commerce dataset.  
It includes loading raw CSV data, implementing a custom Python class for cleaning and aggregation, profiling statistics, data transformations, feature engineering, and saving cleaned outputs.  
The goal is to practice structured data processing, modular coding, and documenting a dataset through a Jupyter notebook format.  
Outputs are organized in subfolders (`/data/outputs/`) for clarity and reproducibility.

## Quick Start

```bash
# Create a virtual environment
python -m venv venv

# Activate environment
# Mac/Linux:
source venv/bin/activate
# Windows:
venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Launch Jupyter Notebook
jupyter notebook

```

## Data Sources

## Primary dataset (1000 Sales Records): ExcelBIAnalytics sample 
 (trimmed to 500 rows for this project)

## Secondary metadata (Product Catalogue / City lookup): 
public open-data catalogue samples & synthetic enhancements created for coursework.

## Run:
```bash
python -m venv venv
source venv/bin/activate   # Mac/Linux
venv\Scripts\activate      # Windows
pip install -r requirements.txt
jupyter notebook
```